{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShubhamSBhat/GNS_Particle_Simulator/blob/main/generalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-JdtGW6d0_1",
        "outputId": "285a5b12-7b03-4756-c9cf-f49c42276676"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4C_TNnfieRQ",
        "outputId": "57dbc202-3e5a-40bf-fc0a-52d6d6e54264"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 287 kB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.0.tar.gz (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 27.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.0-cp37-cp37m-linux_x86_64.whl size=3062823 sha256=6433dbf1c3d468d9104725897ab9c7461469b0f1326a6020d093aceb6ddc88c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/d1/15/8a2f0086896d156654a843fff4bdbeaf621cdd10310a0daad2\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.15.tar.gz (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 34.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.18.5)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.15-cp37-cp37m-linux_x86_64.whl size=1577341 sha256=1044cb2825cb6d5ebfbd96874c39bd547ae899863d451361e62007095c0515ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/68/4d/1414be5c2c622bad35364e13213180797717b6d4b8923936dc\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.15\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "#!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctHuJi0S1mUx"
      },
      "source": [
        "LEARNING TO SIMULATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X8jTt7Fhcel",
        "outputId": "0b675bb1-bc37-4453-c5c8-1cbac711c867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deepmind-research'...\n",
            "remote: Enumerating objects: 2663, done.\u001b[K\n",
            "remote: Total 2663 (delta 0), reused 0 (delta 0), pack-reused 2663\u001b[K\n",
            "Receiving objects: 100% (2663/2663), 91.82 MiB | 28.65 MiB/s, done.\n",
            "Resolving deltas: 100% (1390/1390), done.\n",
            "Checking out files: 100% (760/760), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/deepmind/deepmind-research.git\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZmalUcy1ikl",
        "outputId": "51040932-0216-423c-8f7f-b8698b74e1dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deepmind-research\n"
          ]
        }
      ],
      "source": [
        "cd deepmind-research"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1ULXNbQ1lbm",
        "outputId": "850a80b0-d4df-45f2-a5ca-ddb641fbe263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deepmind-research/learning_to_simulate\n"
          ]
        }
      ],
      "source": [
        "cd learning_to_simulate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nO3eoahz1vub",
        "outputId": "d251c9bf-8917-484a-e5e3-f33552ed0496"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.3.0)\n",
            "Collecting graph-nets>=1.1\n",
            "  Downloading graph_nets-1.1.0.tar.gz (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting tensorflow<2,>=1.15\n",
            "  Downloading tensorflow-1.15.5-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5 MB 1.4 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.21.6)\n",
            "Collecting dm-sonnet<2\n",
            "  Downloading dm_sonnet-1.36-py3-none-any.whl (665 kB)\n",
            "\u001b[K     |████████████████████████████████| 665 kB 64.2 MB/s \n",
            "\u001b[?25hCollecting tensorflow_probability<0.9\n",
            "  Downloading tensorflow_probability-0.8.0-py2.py3-none-any.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 46.3 MB/s \n",
            "\u001b[?25hCollecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (0.1.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (3.2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from graph-nets>=1.1->-r requirements.txt (line 2)) (0.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from graph-nets>=1.1->-r requirements.txt (line 2)) (2.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from graph-nets>=1.1->-r requirements.txt (line 2)) (57.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from graph-nets>=1.1->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.15->-r requirements.txt (line 3)) (3.19.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.15->-r requirements.txt (line 3)) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.15->-r requirements.txt (line 3)) (1.14.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.1 MB/s \n",
            "\u001b[?25hCollecting h5py<=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 50.2 MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 48.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.15->-r requirements.txt (line 3)) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.15->-r requirements.txt (line 3)) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.15->-r requirements.txt (line 3)) (0.2.0)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.15->-r requirements.txt (line 3)) (0.38.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.15->-r requirements.txt (line 3)) (1.50.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 51.8 MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2,>=1.15->-r requirements.txt (line 3)) (2.1.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from dm-sonnet<2->-r requirements.txt (line 5)) (0.5.5)\n",
            "Collecting semantic-version\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability<0.9->-r requirements.txt (line 6)) (4.4.2)\n",
            "Collecting cloudpickle==1.1.1\n",
            "  Downloading cloudpickle-1.1.1-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.15->-r requirements.txt (line 3)) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.15->-r requirements.txt (line 3)) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.15->-r requirements.txt (line 3)) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.15->-r requirements.txt (line 3)) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.15->-r requirements.txt (line 3)) (4.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 9)) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 9)) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 9)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 9)) (1.4.4)\n",
            "Building wheels for collected packages: graph-nets, gast, sklearn\n",
            "  Building wheel for graph-nets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for graph-nets: filename=graph_nets-1.1.0-py3-none-any.whl size=91856 sha256=6c3e1e803fea831b93c4cdb09ef27b37c1abe9c9ca24c8cb7c0943bd75e86b46\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/3d/65/f2e8f0a8d0b28bea5f168fc717261a67303d2183a3e450c812\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=1d9c88e6f8e01cb81c05c42cd26b3dac79864561677d07086fd3e366d07e497b\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=974bfdd4319615e59dbbf789acc2b234dbba7e04c7e085319d53485fcf406243\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/56/cc/4a8bf86613aafd5b7f1b310477667c1fca5c51c3ae4124a003\n",
            "Successfully built graph-nets gast sklearn\n",
            "Installing collected packages: numpy, gast, cloudpickle, tensorflow-probability, semantic-version, h5py, tensorflow-estimator, tensorboard, keras-applications, dm-sonnet, tensorflow, sklearn, graph-nets\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.5.0\n",
            "    Uninstalling cloudpickle-1.5.0:\n",
            "      Successfully uninstalled cloudpickle-1.5.0\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.17.0\n",
            "    Uninstalling tensorflow-probability-0.17.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.17.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.18.5 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.5 which is incompatible.\n",
            "plotnine 0.8.0 requires numpy>=1.19.0, but you have numpy 1.18.5 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.5 which is incompatible.\n",
            "jaxlib 0.3.25+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.18.5 which is incompatible.\n",
            "jax 0.3.25 requires numpy>=1.20, but you have numpy 1.18.5 which is incompatible.\n",
            "gym 0.25.2 requires cloudpickle>=1.2.0, but you have cloudpickle 1.1.1 which is incompatible.\n",
            "distributed 2022.2.0 requires cloudpickle>=1.5.0, but you have cloudpickle 1.1.1 which is incompatible.\n",
            "cmdstanpy 1.0.8 requires numpy>=1.21, but you have numpy 1.18.5 which is incompatible.\u001b[0m\n",
            "Successfully installed cloudpickle-1.1.1 dm-sonnet-1.36 gast-0.2.2 graph-nets-1.1.0 h5py-2.10.0 keras-applications-1.0.8 numpy-1.18.5 semantic-version-2.10.0 sklearn-0.0.post1 tensorboard-1.15.0 tensorflow-1.15.5 tensorflow-estimator-1.15.1 tensorflow-probability-0.8.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r requirements.txt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2StZIaHy2H6R"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "NtdD1uB13XrK"
      },
      "outputs": [],
      "source": [
        "DATASET_NAME=\"Goop\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmrKZanK5b2S",
        "outputId": "cee9401d-19bb-4341-9925-e84682db8856"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-28 13:33:49--  https://storage.googleapis.com/learning-to-simulate-complex-physics/Datasets/Goop/metadata.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.28.128, 74.125.139.128, 173.194.210.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.28.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 362 [application/octet-stream]\n",
            "Saving to: ‘3/Goop/metadata.json’\n",
            "\n",
            "\r3/Goop/metadata.jso   0%[                    ]       0  --.-KB/s               \r3/Goop/metadata.jso 100%[===================>]     362  --.-KB/s    in 0s      \n",
            "\n",
            "2022-11-28 13:33:49 (49.6 MB/s) - ‘3/Goop/metadata.json’ saved [362/362]\n",
            "\n",
            "--2022-11-28 13:33:49--  https://storage.googleapis.com/learning-to-simulate-complex-physics/Datasets/Goop/train.tfrecord\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.28.128, 74.125.139.128, 173.194.210.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.28.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3358535518 (3.1G) [application/octet-stream]\n",
            "Saving to: ‘3/Goop/train.tfrecord’\n",
            "\n",
            "3/Goop/train.tfreco 100%[===================>]   3.13G   152MB/s    in 22s     \n",
            "\n",
            "2022-11-28 13:34:12 (144 MB/s) - ‘3/Goop/train.tfrecord’ saved [3358535518/3358535518]\n",
            "\n",
            "--2022-11-28 13:34:12--  https://storage.googleapis.com/learning-to-simulate-complex-physics/Datasets/Goop/valid.tfrecord\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.28.128, 74.125.139.128, 173.194.210.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.28.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 93682221 (89M) [application/octet-stream]\n",
            "Saving to: ‘3/Goop/valid.tfrecord’\n",
            "\n",
            "3/Goop/valid.tfreco 100%[===================>]  89.34M   125MB/s    in 0.7s    \n",
            "\n",
            "2022-11-28 13:34:13 (125 MB/s) - ‘3/Goop/valid.tfrecord’ saved [93682221/93682221]\n",
            "\n",
            "--2022-11-28 13:34:13--  https://storage.googleapis.com/learning-to-simulate-complex-physics/Datasets/Goop/test.tfrecord\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.28.128, 74.125.139.128, 173.194.210.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.28.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 101783328 (97M) [application/octet-stream]\n",
            "Saving to: ‘3/Goop/test.tfrecord’\n",
            "\n",
            "3/Goop/test.tfrecor 100%[===================>]  97.07M   104MB/s    in 0.9s    \n",
            "\n",
            "2022-11-28 13:34:14 (104 MB/s) - ‘3/Goop/test.tfrecord’ saved [101783328/101783328]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "DATASET_NAME=\"1\"\n",
        "OUTPUT_DIR=\"3/Goop\"\n",
        "\n",
        "BASE_URL=\"https://storage.googleapis.com/learning-to-simulate-complex-physics/Datasets/Goop/\"\n",
        "\n",
        "!mkdir -p \"$OUTPUT_DIR\"\n",
        "for file in [\"metadata.json\", \"train.tfrecord\", \"valid.tfrecord\", \"test.tfrecord\"]:\n",
        "  !wget -O \"$OUTPUT_DIR/$file\" \"$BASE_URL$file\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJd8HOtf8eDe",
        "outputId": "efc0bbd1-8801-4dc6-9aad-ca44f42b0c99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deepmind-research\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uUlQMux_8rA7"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf-mGQwR6iWC",
        "outputId": "938c49e9-b5b5-466a-c63f-7e3ce1069680"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/deepmind-research/learning_to_simulate/train.py\", line 46, in <module>\n",
            "    from learning_to_simulate import learned_simulator\n",
            "  File \"/content/deepmind-research/learning_to_simulate/learned_simulator.py\", line 27, in <module>\n",
            "    import graph_nets as gn\n",
            "ModuleNotFoundError: No module named 'graph_nets'\n"
          ]
        }
      ],
      "source": [
        "!python -m learning_to_simulate.train \\\n",
        "    --data_path= /content/deepmind-research/learning_to_simulate/3/Sand/metadata.json \\\n",
        "    --model_path= /content/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce8VBki5BFzr",
        "outputId": "5abe3370-684b-4b15-e941-9abb06b0e204"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/deepmind-research\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "IyrsA1jK67PB",
        "outputId": "0c19145f-0ac6-4643-fdfe-c371bc086920"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b515251cf5aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcontent\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mSandRamps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'content' is not defined"
          ]
        }
      ],
      "source": [
        "/content/3/SandRamps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UsG1DOxPGK2U"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/rollouts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3HEEQ_AVZR3k",
        "outputId": "63360460-6806-4edf-b723-cc4026125521"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/deepmind-research'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSJR2YI3nG4E",
        "outputId": "15cece1a-9218-4822-a12d-e34916a27d64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'deepmind-research'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "cd deepmind-research"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vl71OAeVc-ts",
        "outputId": "49dc2508-d6f5-48f3-a3a5-67e572bc4a10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "INFO:tensorflow:Using default config.\n",
            "I1127 09:42:39.075711 139886711330688 estimator.py:1800] Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpfgtuam1t', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f39a93ce610>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I1127 09:42:39.076579 139886711330688 estimator.py:212] Using config: {'_model_dir': '/tmp/tmpfgtuam1t', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f39a93ce610>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Entity <function _yield_value at 0x7f39b8416b00> appears to be a generator function. It will not be converted by AutoGraph.\n",
            "W1127 09:42:41.689924 139886711330688 ag_logging.py:146] Entity <function _yield_value at 0x7f39b8416b00> appears to be a generator function. It will not be converted by AutoGraph.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1127 09:42:42.404731 139886711330688 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "W1127 09:42:42.480909 139886711330688 deprecation.py:506] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/sonnet/python/modules/basic.py:127: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W1127 09:42:42.540724 139886711330688 deprecation.py:506] From /usr/local/lib/python3.7/dist-packages/sonnet/python/modules/basic.py:127: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/sonnet/python/modules/basic.py:132: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W1127 09:42:42.541138 139886711330688 deprecation.py:506] From /usr/local/lib/python3.7/dist-packages/sonnet/python/modules/basic.py:132: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /content/deepmind-research/learning_to_simulate/train.py:348: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W1127 09:42:44.085543 139886711330688 deprecation.py:323] From /content/deepmind-research/learning_to_simulate/train.py:348: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1127 09:42:50.686954 139886711330688 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2022-11-27T09:42:50Z\n",
            "I1127 09:42:50.707673 139886711330688 evaluation.py:255] Starting evaluation at 2022-11-27T09:42:50Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1127 09:42:51.956438 139886711330688 monitored_session.py:240] Graph was finalized.\n",
            "2022-11-27 09:42:51.956991: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2022-11-27 09:42:51.961269: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2022-11-27 09:42:51.961504: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x21844c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-11-27 09:42:51.961568: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpfgtuam1t/model.ckpt-5195\n",
            "I1127 09:42:51.962948 139886711330688 saver.py:1284] Restoring parameters from /tmp/tmpfgtuam1t/model.ckpt-5195\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/deepmind-research/learning_to_simulate/train.py\", line 477, in <module>\n",
            "    app.run(main)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/deepmind-research/learning_to_simulate/train.py\", line 449, in main\n",
            "    mode='one_step', split=FLAGS.eval_split))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 480, in evaluate\n",
            "    name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 522, in _actual_eval\n",
            "    return _evaluate()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _evaluate\n",
            "    output_dir=self.eval_dir(name))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1619, in _evaluate_run\n",
            "    config=self._session_config)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/evaluation.py\", line 269, in _evaluate_once\n",
            "    session_creator=session_creator, hooks=hooks) as session:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1014, in __init__\n",
            "    stop_grace_period_secs=stop_grace_period_secs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 725, in __init__\n",
            "    self._sess = _RecoverableSession(self._coordinated_creator)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1207, in __init__\n",
            "    _WrappedSession.__init__(self, self._create_session())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1212, in _create_session\n",
            "    return self._sess_creator.create_session()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 878, in create_session\n",
            "    self.tf_sess = self._session_creator.create_session()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 647, in create_session\n",
            "    init_fn=self._scaffold.init_fn)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/session_manager.py\", line 290, in prepare_session\n",
            "    config=config)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/session_manager.py\", line 204, in _restore_checkpoint\n",
            "    saver.restore(sess, checkpoint_filename_with_path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py\", line 1290, in restore\n",
            "    {self.saver_def.filename_tensor_name: save_path})\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1348, in _run_fn\n",
            "    self._extend_graph()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1388, in _extend_graph\n",
            "    tf_session.ExtendSession(self._session)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python -m learning_to_simulate.train --data_path=/content/deepmind-research/learning_to_simulate/3/Water --model_path=/tmp/tmpfgtuam1t --mode=eval\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU6Z-jnB8xvX",
        "outputId": "4af1ae3f-337d-4b4d-a2dc-7ec464d0489a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "INFO:tensorflow:Using default config.\n",
            "I1128 13:35:52.072684 139814190184320 estimator.py:1800] Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/content/models', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f28c6a405d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I1128 13:35:52.073333 139814190184320 estimator.py:212] Using config: {'_model_dir': '/content/models', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f28c6a405d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1128 13:35:52.567094 139814190184320 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "W1128 13:35:52.638381 139814190184320 deprecation.py:506] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/sonnet/python/modules/basic.py:127: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W1128 13:35:52.700506 139814190184320 deprecation.py:506] From /usr/local/lib/python3.7/dist-packages/sonnet/python/modules/basic.py:127: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/sonnet/python/modules/basic.py:132: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W1128 13:35:52.700859 139814190184320 deprecation.py:506] From /usr/local/lib/python3.7/dist-packages/sonnet/python/modules/basic.py:132: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /content/deepmind-research/learning_to_simulate/train.py:242: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W1128 13:35:54.198611 139814190184320 deprecation.py:323] From /content/deepmind-research/learning_to_simulate/train.py:242: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1128 13:35:54.259544 139814190184320 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1128 13:35:54.795475 139814190184320 monitored_session.py:240] Graph was finalized.\n",
            "2022-11-28 13:35:54.795911: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2022-11-28 13:35:54.814908: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2022-11-28 13:35:54.815194: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1bb1a40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-11-28 13:35:54.815235: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "INFO:tensorflow:Restoring parameters from /content/models/model.ckpt-5195\n",
            "I1128 13:35:54.816420 139814190184320 saver.py:1284] Restoring parameters from /content/models/model.ckpt-5195\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1128 13:35:55.145455 139814190184320 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1128 13:35:55.185712 139814190184320 session_manager.py:502] Done running local_init_op.\n",
            "I1128 13:37:27.789821 139814190184320 train.py:469] Saving: /content/rollouts/Sand/rollout_test_0.pkl.\n",
            "I1128 13:38:34.356027 139814190184320 train.py:469] Saving: /content/rollouts/Sand/rollout_test_1.pkl.\n",
            "I1128 13:42:11.652623 139814190184320 train.py:469] Saving: /content/rollouts/Sand/rollout_test_2.pkl.\n",
            "I1128 13:46:51.682071 139814190184320 train.py:469] Saving: /content/rollouts/Sand/rollout_test_3.pkl.\n",
            "I1128 13:48:53.743796 139814190184320 train.py:469] Saving: /content/rollouts/Sand/rollout_test_4.pkl.\n",
            "2022-11-28 13:51:11.848848: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 103494144 exceeds 10% of system memory.\n",
            "2022-11-28 13:51:12.184366: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 103494144 exceeds 10% of system memory.\n",
            "2022-11-28 13:51:12.496509: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 103494144 exceeds 10% of system memory.\n",
            "2022-11-28 13:51:12.806131: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 103494144 exceeds 10% of system memory.\n",
            "2022-11-28 13:51:13.130963: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 103494144 exceeds 10% of system memory.\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!python -m learning_to_simulate.train \\\n",
        "    --mode=\"eval_rollout\" \\\n",
        "    --data_path=/content/deepmind-research/learning_to_simulate/3/Goop \\\n",
        "    --model_path=/content/models \\\n",
        "    --output_path=/content/rollouts/Sand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bt4A0HgueJDF",
        "outputId": "df4b401b-df95-4090-a5b1-2b8b65e90776"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/deepmind-research\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wc9PUhf5a0Gd",
        "outputId": "b77dca3e-96df-4e8f-e554-fc7713334f19"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/deepmind-research'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlbiq0zPGh-9",
        "outputId": "115357f6-a53e-4210-d614-23405ec71dff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure(1000x500)\n",
            "I1128 13:54:25.897438 139787565156224 animation.py:1112] Animation.save using <class 'matplotlib.animation.FFMpegWriter'>\n",
            "I1128 13:54:25.898445 139787565156224 animation.py:360] MovieWriter._run: running command: ffmpeg -f rawvideo -vcodec rawvideo -s 1000x500 -pix_fmt rgba -r 100.0 -loglevel error -i pipe: -vcodec h264 -pix_fmt yuv420p -y sandongoop5.mp4\n"
          ]
        }
      ],
      "source": [
        "!python -m learning_to_simulate.render_rollout \\\n",
        "    --rollout_path=/content/rollouts/Sand/rollout_test_4.pkl"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4cOeONv5yTgWo2Xmtr+ke",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}